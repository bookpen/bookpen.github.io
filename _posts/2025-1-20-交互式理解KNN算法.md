---
layout: post
title: 交互式理解KNN算法
date: 2025-1-20 00:00:00 +0800
category: tutorial
thumbnail: /style/image/KNN算法.png
icon: book
---
* content
{:toc}

## Ⅰ 背景
KNN(k-nearest neighbors)是一种可以用于分类和回归的算法，
由艾美莉卡统计学家Evelyn Fix和Joseph Lawson Hodges于1951年的论文《歧视性分析，非参数判别：一致性属性》中提出。
KNN这是一种十分简单的机器学习算法，比较适合读者理解，
同样也是笔者第一次尝试使用**交互式工具**来为各位读者呈现这个简单算法。
<img src="style/post_image/交互式理解KNN算法/统计学家.png" alt="统计学家" style="width: 50%; height: auto;">

## Ⅱ 问题描述
KNN算法，中文名为k个最近邻居法，听上去是找到k个最近的邻居就行了，其实这也是这个算法的中心思想。
也正如Evelyn Fix等人的论文名字那样，“歧视性分析”，当然我们也可以理解为“刻板印象”。


一个更加贴近现实的例子，喜欢使用二次元头像的人，可能会有如下判断：
<img src="style/post_image/交互式理解KNN算法/刻板印象.png" style="width: 50%; height: auto;">

1. 男性
2. 18-28岁
2. 喜欢动漫
3. 电脑里有款两个字的二次元开放世界游戏

这就是我们通过“刻板印象”做出的判断，这和KNN算法的步骤很类似。
* 首先，我们平时在网上看到各种各样的信息，让我们了解不同的网络群体，这就是相当于对我们的大脑进行训练。 
* 然后，我们看到有用户使用了某种头像,这就是一个新的样本，我们可以基于之前的经验对这个用户的各种信息进行判断。
* 最后，我们得出了这个用户的各种信息，这就是新样本的预测分类。

那么我们如何利用KNN这个思想来实现基本的分类问题和回归问题呢。
## Ⅲ KNN分类问题
假设我们已经拥有了一系列带标签的样本，为了方便展示，样本特征维度为2，这样我们就可以把样本画在二维坐标系上了，
样本的分布如下图所示。

<center>
<div id="sample_distribution"></div>
</center>
<center>样本分布图</center>

相同颜色的点为一类，总共分为三类{red,blue,green}。

这时，如果加入了一个新的样本，根据已经拥有的样本，我们就可以使用KNN算法确定新样本的类别。
正如KNN算法的中心思想那样，新样本离哪个类别近，我们就将其归于哪个类。
我们可以通过计算新样本与其他所有样本的欧式距离,来确定出最近的k个样本。
<center>
$$ distance = \sqrt{x^2 + y^2} $$
</center>
来确定出最近的k个样本，
然后看看这个k个样本里哪个样本类别占比最多，我们就将新样本归于哪个类别。

不妨通过下面的交互工具，来实现新样本的添加和分类吧。

<center>
<div id="kmeans_cluster"></div>
</center>
<center>KNN分类</center>

* 双击可以添加新样本
* Reset Draw：重置新样本
* Classification：通过寻找最近的5个点对新样本进行分类，并显示分类后的颜色
 

<script type="py" src="/style/post_image/交互式理解KNN算法/bokeh.py" config="/style/pyscript/pyscript.json"></script>